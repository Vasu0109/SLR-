{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"center\" width=100%>\n",
    "    <tr>\n",
    "        <td width=\"15%\">\n",
    "            <img src=\"in_class.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"center\">\n",
    "                <font color=\"#21618C\" size=8px>\n",
    "                    <b> Inclass - Lab <br>(Day 2)\n",
    "                    </b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data set (White wine data)\n",
    "\n",
    "The dataset contains information about several factors describing the quality of white wine. <br> Attribute information: \n",
    "\n",
    "**Fixed_Acidity:** The ph value for titrable acid content (0-7)\n",
    "\n",
    "**Volatile_Acidity:** Measure of acidity due to bacteria\n",
    "\n",
    "**Citric_Acid:** Amount of citric acid present in wine\n",
    "\n",
    "**Residual_Sugar:** Amount of grape sugar in gms/litre\n",
    "\n",
    "**Chlorides:** Amount of chlorides present in wine\n",
    "\n",
    "**Free_Sulfur-dioxide:** Amount of SO2 that is not bound to other molecules\n",
    "\n",
    "**Total_Sulfur-dioxide:** Portion of SO2 that is free in the wine plus the portion that is bound to other chemicals in the wine\n",
    "\n",
    "**Density:** Density of wine (gms/cm<sup>3</sup>)\n",
    "\n",
    "**pH:** The pH value of wine (0-14)\n",
    "\n",
    "**Sulphates:** Amount of salts of sulphuric acid \n",
    "\n",
    "**Alcohol:** Alcohol content in percentage\n",
    "\n",
    "**Quality:** Wine quality \n",
    "\n",
    "Data citation: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "1. **[Feature Transformation](#trans)**\n",
    "2. **[Feature Selection](#sel)**\n",
    "3. **[Model Validation](#cv)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the first dataset and check the first two observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your data\n",
    "# type your code here\n",
    "df = pd.read_csv(\"whitewine.csv\",sep = \";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types of variables\n",
    "# type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's begin with some hands-on practice exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trans\"> </a>\n",
    "## 1. Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We shall use the wine quality dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>1. Does the variable 'volatile acidity' need transformation ?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13938315393329148"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "from scipy import stats\n",
    "a = np.log(df[\"volatile acidity\"])\n",
    "a.skew()\n",
    "#Log transformation is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>2. How can we reduce skewness of variable 'Residual_Sugar'?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1611568975182972"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "df[\"residual sugar\"].skew()\n",
    "v = np.log(df[\"residual sugar\"])\n",
    "v.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>3. Are there features in the dataset that add little to no information ?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.282</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.280</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   174.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 17 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:09:13</td>     <th>  Log-Likelihood:    </th> <td> -5543.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4898</td>      <th>  AIC:               </th> <td>1.111e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4886</td>      <th>  BIC:               </th> <td>1.119e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>  150.1928</td> <td>   18.804</td> <td>    7.987</td> <td> 0.000</td> <td>  113.328</td> <td>  187.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.0655</td> <td>    0.021</td> <td>    3.139</td> <td> 0.002</td> <td>    0.025</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -1.8632</td> <td>    0.114</td> <td>  -16.373</td> <td> 0.000</td> <td>   -2.086</td> <td>   -1.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>    0.0221</td> <td>    0.096</td> <td>    0.231</td> <td> 0.818</td> <td>   -0.166</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0815</td> <td>    0.008</td> <td>   10.825</td> <td> 0.000</td> <td>    0.067</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -0.2473</td> <td>    0.547</td> <td>   -0.452</td> <td> 0.651</td> <td>   -1.319</td> <td>    0.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0037</td> <td>    0.001</td> <td>    4.422</td> <td> 0.000</td> <td>    0.002</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0003</td> <td>    0.000</td> <td>   -0.756</td> <td> 0.450</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td> -150.2842</td> <td>   19.075</td> <td>   -7.879</td> <td> 0.000</td> <td> -187.679</td> <td> -112.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.6863</td> <td>    0.105</td> <td>    6.513</td> <td> 0.000</td> <td>    0.480</td> <td>    0.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    0.6315</td> <td>    0.100</td> <td>    6.291</td> <td> 0.000</td> <td>    0.435</td> <td>    0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.1935</td> <td>    0.024</td> <td>    7.988</td> <td> 0.000</td> <td>    0.146</td> <td>    0.241</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>114.161</td> <th>  Durbin-Watson:     </th> <td>   1.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 251.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.073</td>  <th>  Prob(JB):          </th> <td>2.28e-55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.101</td>  <th>  Cond. No.          </th> <td>3.74e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.74e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.282\n",
       "Model:                            OLS   Adj. R-squared:                  0.280\n",
       "Method:                 Least Squares   F-statistic:                     174.3\n",
       "Date:                Fri, 17 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        15:09:13   Log-Likelihood:                -5543.7\n",
       "No. Observations:                4898   AIC:                         1.111e+04\n",
       "Df Residuals:                    4886   BIC:                         1.119e+04\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                  150.1928     18.804      7.987      0.000     113.328     187.057\n",
       "fixed acidity            0.0655      0.021      3.139      0.002       0.025       0.106\n",
       "volatile acidity        -1.8632      0.114    -16.373      0.000      -2.086      -1.640\n",
       "citric acid              0.0221      0.096      0.231      0.818      -0.166       0.210\n",
       "residual sugar           0.0815      0.008     10.825      0.000       0.067       0.096\n",
       "chlorides               -0.2473      0.547     -0.452      0.651      -1.319       0.824\n",
       "free sulfur dioxide      0.0037      0.001      4.422      0.000       0.002       0.005\n",
       "total sulfur dioxide    -0.0003      0.000     -0.756      0.450      -0.001       0.000\n",
       "density               -150.2842     19.075     -7.879      0.000    -187.679    -112.890\n",
       "pH                       0.6863      0.105      6.513      0.000       0.480       0.893\n",
       "sulphates                0.6315      0.100      6.291      0.000       0.435       0.828\n",
       "alcohol                  0.1935      0.024      7.988      0.000       0.146       0.241\n",
       "==============================================================================\n",
       "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
       "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
       "Kurtosis:                       4.101   Cond. No.                     3.74e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.74e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "x = df.drop(columns = \"quality\")\n",
    "y = df[\"quality\"]\n",
    "from statsmodels import api\n",
    "xc = api.add_constant(x)\n",
    "ols_model =  api.OLS(y,xc)\n",
    "linear_model = ols_model.fit()\n",
    "y_pred = linear_model.predict()\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#critic acid,chlorides,total sulfur dioxide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>4. Which transformation method is best suited to treat the skewness in variable 'alcohol'?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.310134622964236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "df[\"alcohol\"].skew()\n",
    "a = np.log(df[\"alcohol\"])\n",
    "a.skew()\n",
    "# we are able to reduce the skewness by doing log transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>5. Does scaling the feature 'pH' lead to better prediction when considering a full model ?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WELCOME\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.282</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.280</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   174.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 17 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:09:14</td>     <th>  Log-Likelihood:    </th> <td> -5543.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4898</td>      <th>  AIC:               </th> <td>1.111e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4886</td>      <th>  BIC:               </th> <td>1.119e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>  152.3811</td> <td>   19.013</td> <td>    8.015</td> <td> 0.000</td> <td>  115.108</td> <td>  189.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.0655</td> <td>    0.021</td> <td>    3.139</td> <td> 0.002</td> <td>    0.025</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -1.8632</td> <td>    0.114</td> <td>  -16.373</td> <td> 0.000</td> <td>   -2.086</td> <td>   -1.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>    0.0221</td> <td>    0.096</td> <td>    0.231</td> <td> 0.818</td> <td>   -0.166</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0815</td> <td>    0.008</td> <td>   10.825</td> <td> 0.000</td> <td>    0.067</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -0.2473</td> <td>    0.547</td> <td>   -0.452</td> <td> 0.651</td> <td>   -1.319</td> <td>    0.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0037</td> <td>    0.001</td> <td>    4.422</td> <td> 0.000</td> <td>    0.002</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0003</td> <td>    0.000</td> <td>   -0.756</td> <td> 0.450</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td> -150.2842</td> <td>   19.075</td> <td>   -7.879</td> <td> 0.000</td> <td> -187.679</td> <td> -112.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.1036</td> <td>    0.016</td> <td>    6.513</td> <td> 0.000</td> <td>    0.072</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    0.6315</td> <td>    0.100</td> <td>    6.291</td> <td> 0.000</td> <td>    0.435</td> <td>    0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.1935</td> <td>    0.024</td> <td>    7.988</td> <td> 0.000</td> <td>    0.146</td> <td>    0.241</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>114.161</td> <th>  Durbin-Watson:     </th> <td>   1.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 251.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.073</td>  <th>  Prob(JB):          </th> <td>2.28e-55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.101</td>  <th>  Cond. No.          </th> <td>3.76e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.76e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.282\n",
       "Model:                            OLS   Adj. R-squared:                  0.280\n",
       "Method:                 Least Squares   F-statistic:                     174.3\n",
       "Date:                Fri, 17 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        15:09:14   Log-Likelihood:                -5543.7\n",
       "No. Observations:                4898   AIC:                         1.111e+04\n",
       "Df Residuals:                    4886   BIC:                         1.119e+04\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                  152.3811     19.013      8.015      0.000     115.108     189.655\n",
       "fixed acidity            0.0655      0.021      3.139      0.002       0.025       0.106\n",
       "volatile acidity        -1.8632      0.114    -16.373      0.000      -2.086      -1.640\n",
       "citric acid              0.0221      0.096      0.231      0.818      -0.166       0.210\n",
       "residual sugar           0.0815      0.008     10.825      0.000       0.067       0.096\n",
       "chlorides               -0.2473      0.547     -0.452      0.651      -1.319       0.824\n",
       "free sulfur dioxide      0.0037      0.001      4.422      0.000       0.002       0.005\n",
       "total sulfur dioxide    -0.0003      0.000     -0.756      0.450      -0.001       0.000\n",
       "density               -150.2842     19.075     -7.879      0.000    -187.679    -112.890\n",
       "pH                       0.1036      0.016      6.513      0.000       0.072       0.135\n",
       "sulphates                0.6315      0.100      6.291      0.000       0.435       0.828\n",
       "alcohol                  0.1935      0.024      7.988      0.000       0.146       0.241\n",
       "==============================================================================\n",
       "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
       "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
       "Kurtosis:                       4.101   Cond. No.                     3.76e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.76e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "sns.boxplot(df[\"pH\"])\n",
    "plt.show()\n",
    "df[\"pH\"].skew()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "df[\"pH\"] = ss.fit_transform(df[[\"pH\"]])\n",
    "x = df.drop(columns = \"quality\")\n",
    "y = df[\"quality\"]\n",
    "from statsmodels import api\n",
    "xc = api.add_constant(x)\n",
    "ols_model =  api.OLS(y,xc)\n",
    "linear_model = ols_model.fit()\n",
    "y_pred = linear_model.predict()\n",
    "linear_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the ph value does not improving the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>6. What could be done to resolve the issue of multicollinearity if present?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your code here\n",
    "# we can vif and get the values for each column if values greater than 5 we can remove those columns to resolve multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>7.  Fit a full model. Is the assumption for normality of residuals violated ?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07296691768266028"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "resid = linear_model.resid\n",
    "resid.skew()\n",
    "# residuals are already normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>8. Does the transformation of variable 'citric acid' affect the performance of prediction model?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.282</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.281</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   174.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 17 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:09:15</td>     <th>  Log-Likelihood:    </th> <td> -5542.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4898</td>      <th>  AIC:               </th> <td>1.111e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4886</td>      <th>  BIC:               </th> <td>1.119e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>  153.7758</td> <td>   19.001</td> <td>    8.093</td> <td> 0.000</td> <td>  116.526</td> <td>  191.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.0618</td> <td>    0.021</td> <td>    2.956</td> <td> 0.003</td> <td>    0.021</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -1.8264</td> <td>    0.116</td> <td>  -15.798</td> <td> 0.000</td> <td>   -2.053</td> <td>   -1.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>    0.1597</td> <td>    0.110</td> <td>    1.452</td> <td> 0.147</td> <td>   -0.056</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0818</td> <td>    0.008</td> <td>   10.871</td> <td> 0.000</td> <td>    0.067</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -0.3194</td> <td>    0.546</td> <td>   -0.584</td> <td> 0.559</td> <td>   -1.391</td> <td>    0.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0037</td> <td>    0.001</td> <td>    4.400</td> <td> 0.000</td> <td>    0.002</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0003</td> <td>    0.000</td> <td>   -0.837</td> <td> 0.403</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td> -151.7124</td> <td>   19.064</td> <td>   -7.958</td> <td> 0.000</td> <td> -189.086</td> <td> -114.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.1052</td> <td>    0.016</td> <td>    6.614</td> <td> 0.000</td> <td>    0.074</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    0.6259</td> <td>    0.100</td> <td>    6.235</td> <td> 0.000</td> <td>    0.429</td> <td>    0.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.1902</td> <td>    0.024</td> <td>    7.845</td> <td> 0.000</td> <td>    0.143</td> <td>    0.238</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>115.056</td> <th>  Durbin-Watson:     </th> <td>   1.620</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 254.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.075</td>  <th>  Prob(JB):          </th> <td>6.97e-56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.105</td>  <th>  Cond. No.          </th> <td>3.76e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.76e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.282\n",
       "Model:                            OLS   Adj. R-squared:                  0.281\n",
       "Method:                 Least Squares   F-statistic:                     174.6\n",
       "Date:                Fri, 17 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        15:09:15   Log-Likelihood:                -5542.7\n",
       "No. Observations:                4898   AIC:                         1.111e+04\n",
       "Df Residuals:                    4886   BIC:                         1.119e+04\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                  153.7758     19.001      8.093      0.000     116.526     191.026\n",
       "fixed acidity            0.0618      0.021      2.956      0.003       0.021       0.103\n",
       "volatile acidity        -1.8264      0.116    -15.798      0.000      -2.053      -1.600\n",
       "citric acid              0.1597      0.110      1.452      0.147      -0.056       0.375\n",
       "residual sugar           0.0818      0.008     10.871      0.000       0.067       0.097\n",
       "chlorides               -0.3194      0.546     -0.584      0.559      -1.391       0.752\n",
       "free sulfur dioxide      0.0037      0.001      4.400      0.000       0.002       0.005\n",
       "total sulfur dioxide    -0.0003      0.000     -0.837      0.403      -0.001       0.000\n",
       "density               -151.7124     19.064     -7.958      0.000    -189.086    -114.339\n",
       "pH                       0.1052      0.016      6.614      0.000       0.074       0.136\n",
       "sulphates                0.6259      0.100      6.235      0.000       0.429       0.823\n",
       "alcohol                  0.1902      0.024      7.845      0.000       0.143       0.238\n",
       "==============================================================================\n",
       "Omnibus:                      115.056   Durbin-Watson:                   1.620\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              254.007\n",
       "Skew:                           0.075   Prob(JB):                     6.97e-56\n",
       "Kurtosis:                       4.105   Cond. No.                     3.76e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.76e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "df[\"citric acid\"] = np.sqrt(df[\"citric acid\"])\n",
    "df[\"citric acid\"].skew()\n",
    "x = df.drop(columns = \"quality\")\n",
    "y = df[\"quality\"]\n",
    "from statsmodels import api\n",
    "xc = api.add_constant(x)\n",
    "ols_model =  api.OLS(y,xc)\n",
    "linear_model = ols_model.fit()\n",
    "y_pred = linear_model.predict()\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change even after transforming the citric acid variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>9. Fit a full model. Check whether variable has linear relationship with the wine quality<br></b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e6b934f490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# type your code here\n",
    "x = df.drop(columns = \"quality\")\n",
    "y = df[\"quality\"]\n",
    "from statsmodels import api\n",
    "xc = api.add_constant(x)\n",
    "ols_model =  api.OLS(y,xc)\n",
    "linear_model = ols_model.fit()\n",
    "y_pred = linear_model.predict()\n",
    "linear_model.summary()\n",
    "plt.scatter(y_pred,resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variabes are not dependent on the target varibale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sel\"> </a>\n",
    "## 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>10. Find the top five significant variables from the dataset using forward selection technique. Also display the R-squared score for the model built using these five variables.</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2508657069945014"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 100)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=  LinearRegression()\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "lr_forward = SequentialFeatureSelector(estimator=lr,n_features_to_select=5,direction=\"forward\")\n",
    "sfs = lr_forward.fit(x,y)\n",
    "a = sfs.get_support()\n",
    "dg = pd.DataFrame()\n",
    "dg[\"bool\"] = a\n",
    "dg[\"columns\"] = x.columns\n",
    "dg[\"columns\"]\n",
    "a = dg[dg[\"bool\"] == True][\"columns\"].to_frame()\n",
    "for_features = list(a[\"columns\"])\n",
    "for_features\n",
    "\n",
    "lr.fit(x_train[for_features],y_train)\n",
    "y_pred_train = lr.predict(x_train[for_features])\n",
    "y_pred_test  = lr.predict(x_test[for_features])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train_for = mean_squared_error(y_pred_train,y_train)\n",
    "mse_test_for = mean_squared_error(y_pred_test,y_test)\n",
    "rmse_train_for = np.sqrt(mse_train_for)\n",
    "rmse_test_for = np.sqrt(mse_test_for)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                        <b>11. Find the top five significant variables from the dataset using backward elimination technique. Also display the R-squared score for the model built using these five variables.<br><br> Compare the R-squared value obtained from question 10 with the value obtained using backward elimination.</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2508657069945014"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=  LinearRegression()\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "lr_forward = SequentialFeatureSelector(estimator=lr,n_features_to_select=5,direction=\"backward\")\n",
    "sfs = lr_forward.fit(x,y)\n",
    "a = sfs.get_support()\n",
    "dg = pd.DataFrame()\n",
    "dg[\"bool\"] = a\n",
    "dg[\"columns\"] = x.columns\n",
    "dg[\"columns\"]\n",
    "a = dg[dg[\"bool\"] == True][\"columns\"].to_frame()\n",
    "for_features = list(a[\"columns\"])\n",
    "for_features\n",
    "\n",
    "lr.fit(x_train[for_features],y_train)\n",
    "y_pred_train = lr.predict(x_train[for_features])\n",
    "y_pred_test  = lr.predict(x_test[for_features])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train_for = mean_squared_error(y_pred_train,y_train)\n",
    "mse_test_for = mean_squared_error(y_pred_test,y_test)\n",
    "rmse_train_for = np.sqrt(mse_train_for)\n",
    "rmse_test_for = np.sqrt(mse_test_for)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both the r squared values are the same when using forward and backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>12. Find the best set of significant variables from the dataset using forward selection technique such that the selected set should have 2 to 6 features. Also display the R-squared score for the model built using the selected variables</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['volatile acidity',\n",
       "  'residual sugar',\n",
       "  'free sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'alcohol'],\n",
       " [0.28455406605983047,\n",
       "  0.24863419647581853,\n",
       "  0.533436093698046,\n",
       "  0.49863232594349366])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,test_size=.3,random_state=100)\n",
    "lr_forward=sfs(estimator=lr, k_features=(2,6), forward= True)\n",
    "sfs_forward=lr_forward.fit(x,y)\n",
    "features_forward=list(sfs_forward.k_feature_names_)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from  sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error,r2_score\n",
    "lr = LinearRegression()\n",
    "lr.fit(xtrain[features_forward],ytrain)\n",
    "y_pred_train= lr.predict(xtrain[features_forward])\n",
    "y_pred_test = lr.predict(xtest[features_forward])\n",
    "train_r2_for= r2_score(ytrain,y_pred_train)\n",
    "test_r2_for= r2_score(ytest,y_pred_test)\n",
    "\n",
    "train_mse_for= mean_squared_error(ytrain,y_pred_train)\n",
    "test_mse_for= mean_squared_error(ytest,y_pred_test)\n",
    "train_rmse_for= np.sqrt(train_r2_for)\n",
    "test_rmse_for= np.sqrt(test_r2_for)\n",
    "res_for=[train_r2_for,test_r2_for,train_rmse_for,test_rmse_for]\n",
    "features_forward,res_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>13. Find the best set of significant variables from the dataset using forward selection technique. Also display the R-squared score for the model built using the selected variables.</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['volatile acidity',\n",
       "  'residual sugar',\n",
       "  'free sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol'],\n",
       " [0.2910200200382689,\n",
       "  0.2493562723198096,\n",
       "  0.5394627142243187,\n",
       "  0.4993558574001206])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,test_size=.3,random_state=100)\n",
    "lr_forward=sfs(estimator=lr, k_features='best', forward= True)\n",
    "sfs_forward=lr_forward.fit(x,y)\n",
    "features_forward=list(sfs_forward.k_feature_names_)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from  sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error,r2_score\n",
    "lr = LinearRegression()\n",
    "lr.fit(xtrain[features_forward],ytrain)\n",
    "y_pred_train= lr.predict(xtrain[features_forward])\n",
    "y_pred_test = lr.predict(xtest[features_forward])\n",
    "train_r2_for= r2_score(ytrain,y_pred_train)\n",
    "test_r2_for= r2_score(ytest,y_pred_test)\n",
    "\n",
    "train_mse_for= mean_squared_error(ytrain,y_pred_train)\n",
    "test_mse_for= mean_squared_error(ytest,y_pred_test)\n",
    "train_rmse_for= np.sqrt(train_r2_for)\n",
    "test_rmse_for= np.sqrt(test_r2_for)\n",
    "res_for=[train_r2_for,test_r2_for,train_rmse_for,test_rmse_for]\n",
    "features_forward,res_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>14. Find the best set of significant variables from the dataset using backward elimination technique. Also display the R-squared score for the model built using the selected variables. <br><br>Compare the R-squared value obtained from question 13 with the value obtained using backward elimination.</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['volatile acidity',\n",
       "  'residual sugar',\n",
       "  'free sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol'],\n",
       " [0.2910200200382689,\n",
       "  0.2493562723198096,\n",
       "  0.5394627142243187,\n",
       "  0.4993558574001206])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,test_size=.3,random_state=100)\n",
    "lr_forward=sfs(estimator=lr, k_features='best', forward= False)\n",
    "sfs_forward=lr_forward.fit(x,y)\n",
    "features_forward=list(sfs_forward.k_feature_names_)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from  sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error,r2_score\n",
    "lr = LinearRegression()\n",
    "lr.fit(xtrain[features_forward],ytrain)\n",
    "y_pred_train= lr.predict(xtrain[features_forward])\n",
    "y_pred_test = lr.predict(xtest[features_forward])\n",
    "train_r2_for= r2_score(ytrain,y_pred_train)\n",
    "test_r2_for= r2_score(ytest,y_pred_test)\n",
    "\n",
    "train_mse_for= mean_squared_error(ytrain,y_pred_train)\n",
    "test_mse_for= mean_squared_error(ytest,y_pred_test)\n",
    "train_rmse_for= np.sqrt(train_r2_for)\n",
    "test_rmse_for= np.sqrt(test_r2_for)\n",
    "res_for=[train_r2_for,test_r2_for,train_rmse_for,test_rmse_for]\n",
    "features_forward,res_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>15. Find the best set of significant variables from the dataset among all the possible subsets of the variables. Build a linear regression model using the best subset and find the R-Squared value for that model.</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2910200200382689"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,test_size=.3,random_state=100)\n",
    "lr_forward=sfs(estimator=lr, k_features='best', forward= False)\n",
    "sfs_forward=lr_forward.fit(x,y)\n",
    "features_forward=list(sfs_forward.k_feature_names_)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from  sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error,r2_score\n",
    "lr = LinearRegression()\n",
    "lr.fit(xtrain[features_forward],ytrain)\n",
    "y_pred_train= lr.predict(xtrain[features_forward])\n",
    "y_pred_test = lr.predict(xtest[features_forward])\n",
    "train_r2_for= r2_score(ytrain,y_pred_train)\n",
    "test_r2_for= r2_score(ytest,y_pred_test)\n",
    "\n",
    "train_mse_for= mean_squared_error(ytrain,y_pred_train)\n",
    "test_mse_for= mean_squared_error(ytest,y_pred_test)\n",
    "train_rmse_for= np.sqrt(train_r2_for)\n",
    "test_rmse_for= np.sqrt(test_r2_for)\n",
    "res_for=[train_r2_for,test_r2_for,train_rmse_for,test_rmse_for]\n",
    "train_r2_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>16. Calculate the RMSE for the train set and test set for the model created using the top 5 variables obtained from forward selection in question 10. Check if the model is overfitted on the train set or not. If yes, then why do you think so?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7581154268405418\n",
      "0.7522081168924998\n"
     ]
    }
   ],
   "source": [
    "# type your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 100)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=  LinearRegression()\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "lr_forward = SequentialFeatureSelector(estimator=lr,n_features_to_select=5,direction=\"forward\")\n",
    "sfs = lr_forward.fit(x,y)\n",
    "a = sfs.get_support()\n",
    "dg = pd.DataFrame()\n",
    "dg[\"bool\"] = a\n",
    "dg[\"columns\"] = x.columns\n",
    "dg[\"columns\"]\n",
    "a = dg[dg[\"bool\"] == True][\"columns\"].to_frame()\n",
    "for_features = list(a[\"columns\"])\n",
    "for_features\n",
    "\n",
    "lr.fit(x_train[for_features],y_train)\n",
    "y_pred_train = lr.predict(x_train[for_features])\n",
    "y_pred_test  = lr.predict(x_test[for_features])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train_for = mean_squared_error(y_pred_train,y_train)\n",
    "mse_test_for = mean_squared_error(y_pred_test,y_test)\n",
    "rmse_train_for = np.sqrt(mse_train_for)\n",
    "rmse_test_for = np.sqrt(mse_test_for)\n",
    "print(rmse_train_for)\n",
    "print(rmse_test_for)\n",
    "\n",
    "# the model is not overfitted with the train data the model gives approximately the same result for both the train and test set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cv\"> </a>\n",
    "## 3. Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>17. Create a new feature based on the 'pH' which tells whether wine is acidic, basic or neutral. Will this variable significantly contribute to the model?</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.283</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.282</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   160.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 17 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:12:47</td>     <th>  Log-Likelihood:    </th> <td> -5538.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4898</td>      <th>  AIC:               </th> <td>1.110e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4885</td>      <th>  BIC:               </th> <td>1.119e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>  156.5201</td> <td>   19.013</td> <td>    8.232</td> <td> 0.000</td> <td>  119.245</td> <td>  193.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.0639</td> <td>    0.021</td> <td>    3.056</td> <td> 0.002</td> <td>    0.023</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -1.8195</td> <td>    0.116</td> <td>  -15.745</td> <td> 0.000</td> <td>   -2.046</td> <td>   -1.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>    0.1588</td> <td>    0.110</td> <td>    1.444</td> <td> 0.149</td> <td>   -0.057</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0825</td> <td>    0.008</td> <td>   10.972</td> <td> 0.000</td> <td>    0.068</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -0.2611</td> <td>    0.547</td> <td>   -0.478</td> <td> 0.633</td> <td>   -1.332</td> <td>    0.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0037</td> <td>    0.001</td> <td>    4.382</td> <td> 0.000</td> <td>    0.002</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0003</td> <td>    0.000</td> <td>   -0.701</td> <td> 0.484</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td> -154.3804</td> <td>   19.075</td> <td>   -8.093</td> <td> 0.000</td> <td> -191.776</td> <td> -116.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.1492</td> <td>    0.022</td> <td>    6.640</td> <td> 0.000</td> <td>    0.105</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    0.6175</td> <td>    0.100</td> <td>    6.153</td> <td> 0.000</td> <td>    0.421</td> <td>    0.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.1868</td> <td>    0.024</td> <td>    7.697</td> <td> 0.000</td> <td>    0.139</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ph_encoded</th>           <td>   -0.1017</td> <td>    0.037</td> <td>   -2.771</td> <td> 0.006</td> <td>   -0.174</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>116.099</td> <th>  Durbin-Watson:     </th> <td>   1.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 258.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.071</td>  <th>  Prob(JB):          </th> <td>6.51e-57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.117</td>  <th>  Cond. No.          </th> <td>3.77e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.77e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.283\n",
       "Model:                            OLS   Adj. R-squared:                  0.282\n",
       "Method:                 Least Squares   F-statistic:                     160.9\n",
       "Date:                Fri, 17 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        15:12:47   Log-Likelihood:                -5538.9\n",
       "No. Observations:                4898   AIC:                         1.110e+04\n",
       "Df Residuals:                    4885   BIC:                         1.119e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                  156.5201     19.013      8.232      0.000     119.245     193.795\n",
       "fixed acidity            0.0639      0.021      3.056      0.002       0.023       0.105\n",
       "volatile acidity        -1.8195      0.116    -15.745      0.000      -2.046      -1.593\n",
       "citric acid              0.1588      0.110      1.444      0.149      -0.057       0.374\n",
       "residual sugar           0.0825      0.008     10.972      0.000       0.068       0.097\n",
       "chlorides               -0.2611      0.547     -0.478      0.633      -1.332       0.810\n",
       "free sulfur dioxide      0.0037      0.001      4.382      0.000       0.002       0.005\n",
       "total sulfur dioxide    -0.0003      0.000     -0.701      0.484      -0.001       0.000\n",
       "density               -154.3804     19.075     -8.093      0.000    -191.776    -116.984\n",
       "pH                       0.1492      0.022      6.640      0.000       0.105       0.193\n",
       "sulphates                0.6175      0.100      6.153      0.000       0.421       0.814\n",
       "alcohol                  0.1868      0.024      7.697      0.000       0.139       0.234\n",
       "Ph_encoded              -0.1017      0.037     -2.771      0.006      -0.174      -0.030\n",
       "==============================================================================\n",
       "Omnibus:                      116.099   Durbin-Watson:                   1.621\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              258.747\n",
       "Skew:                           0.071   Prob(JB):                     6.51e-57\n",
       "Kurtosis:                       4.117   Cond. No.                     3.77e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.77e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "a = pd.cut(df.pH, bins=3,\n",
    "           labels=[0, 1,2])\n",
    "df[\"Ph_encoded\"] = a\n",
    "x = df.drop(columns = \"quality\")\n",
    "y = df[\"quality\"]\n",
    "from statsmodels import api\n",
    "xc = api.add_constant(x)\n",
    "ols_model =  api.OLS(y,xc)\n",
    "linear_model = ols_model.fit()\n",
    "y_pred = linear_model.predict()\n",
    "linear_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no change in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>18. Fit the a full model. Validate the model using cross validation method</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28042007608191977"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "np.mean(cross_val_score(lr,x_train,y_train,cv = 10,scoring = 'r2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>19. Fit the a full model. Validate the model using 5 - fold cross validation</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2794426456695615"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "a = cross_val_score(lr,x_train,y_train,cv = 5,scoring = 'r2')\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"question_icon.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>20. Fit the a full model. Validate the model using leave one out cross validation</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "lo = LeaveOneOut()\n",
    "cross_val_score(lr,x_train,y_train,cv = lo,scoring = \"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
